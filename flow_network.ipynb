{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtiOnVDLQrvyVc0EkLdaMx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbaremoney/goldenTicket/blob/main/flow_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K98kq_yq4lXy"
      },
      "outputs": [],
      "source": [
        "!pip install medmnist --q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYxWZLZ0lfhr"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import v2\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import random\n",
        "import torch.autograd as autograd\n",
        "import math\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "from matplotlib import pyplot as plt\n",
        "from itertools import combinations_with_replacement"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5yg8xif5QQl",
        "outputId": "1dd25724-8226-4945-9bfa-35be4d3744c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsJE5q465fF_",
        "outputId": "89fbf077-d7e5-4315-bb7d-53f33725c4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getTrainingDataLoaders(dataset_name, download=True, BATCH_SIZE=128):\n",
        "    \"\"\"\n",
        "    Handling data preprocessing & loading.\n",
        "\n",
        "    Args:\n",
        "      dataset_name (str): name of dataset to be loaded\n",
        "      download (bool): Whether or not you'll download the dataset locally\n",
        "      BATCH_SIZE (int): batch size to be used during training\n",
        "\n",
        "    Returns:\n",
        "      info (dict): dictionary directly from medmnist.INFO containing metadata\n",
        "      task (str): string indicating type of task ie 'binary-class', 'multi-class'\n",
        "      n_classes (int): int indicating number of classes in dataset\n",
        "      train_loader (DataLoader): provides iterator over training dataset, provides batches\n",
        "      train_loader_at_eval (DataLoader): evaluation version of train_loader, double batch size\n",
        "      test_loader (DataLoader): test version of train_loader, similar to train_loader_at_eval\n",
        "\n",
        "    \"\"\"\n",
        "    data_flag = dataset_name\n",
        "\n",
        "    info = INFO[data_flag]\n",
        "    task = info['task']\n",
        "    n_channels = info['n_channels']\n",
        "    n_classes = len(info['label'])\n",
        "\n",
        "    DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "    # RGBtransform = transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x)\n",
        "\n",
        "    # preprocessing\n",
        "    if n_channels == 3:\n",
        "        data_transform = v2.Compose([\n",
        "            v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "            v2.Normalize(mean=[.5], std=[.5])\n",
        "        ])\n",
        "\n",
        "    if n_channels == 1:\n",
        "        data_transform = v2.Compose([\n",
        "            v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "            v2.RGB(),\n",
        "            v2.Normalize(mean=[.5], std=[.5])\n",
        "        ])\n",
        "\n",
        "    # load the data\n",
        "    train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
        "    test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
        "\n",
        "    pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "    # encapsulate data into dataloader form\n",
        "    train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "    return info, task, n_classes, train_loader, train_loader_at_eval, test_loader"
      ],
      "metadata": {
        "id": "6Odkl4L8l4Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassicNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes,bias=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            *[z for l in layer_sizes\n",
        "              for z in [nn.Linear(l[0], l[1],bias=bias), nn.ReLU()]][:-1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n"
      ],
      "metadata": {
        "id": "8QxsRrr06Wlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up signed Kaiming initialization.\n",
        "def signed_kaiming_constant_(tensor, a=0, mode='fan_in', nonlinearity='relu', k=0.5, sparsity=0):\n",
        "\n",
        "    fan = nn.init._calculate_correct_fan(tensor, mode)  # calculating correct fan, depends on shape and type of nn\n",
        "    gain = nn.init.calculate_gain(nonlinearity, a)\n",
        "    std = (gain / math.sqrt(fan))\n",
        "    # scale by (1/sqrt(k))\n",
        "    if k != 0:\n",
        "        std *= (1 / math.sqrt(k))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tensor.uniform_(-std, std)\n",
        "        if sparsity > 0:\n",
        "            mask = (torch.rand_like(tensor) > sparsity).float()  # Keeps (1 - sparsity)% weights\n",
        "\n",
        "            tensor *= mask\n",
        "\n",
        "        return tensor"
      ],
      "metadata": {
        "id": "Zqm1qpow6wb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GetSubnet(autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, scores, k):\n",
        "\n",
        "        # Get the subnetwork by sorting the scores and using the top k%\n",
        "        out = scores.clone()\n",
        "        _, idx = scores.flatten().sort()\n",
        "        j = int((1-k) * scores.numel())\n",
        "\n",
        "        # flat_out and out access the same memory.\n",
        "        flat_out = out.flatten()\n",
        "        flat_out[idx[:j]] = 0\n",
        "        flat_out[idx[j:]] = 1\n",
        "\n",
        "        return out\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad):\n",
        "\n",
        "        # send the gradient g straight-through on the backward pass.\n",
        "        return grad, None"
      ],
      "metadata": {
        "id": "fiEOrdQS7sK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearSubnet(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, bias=True, k=0.5, init=signed_kaiming_constant_, **kwargs):\n",
        "        super().__init__(in_features, out_features, bias if isinstance(bias, bool) else True, **kwargs)\n",
        "\n",
        "        self.k = k\n",
        "        self.popup_scores = nn.Parameter(torch.randn(out_features, in_features), requires_grad=True)\n",
        "        self.bias_popup_scores = nn.Parameter(torch.randn(out_features), requires_grad=True)\n",
        "        self.popup_scores_extra = nn.Parameter(torch.randn(out_features, in_features), requires_grad=True)\n",
        "        self.bias_popup_scores_extra = nn.Parameter(torch.randn(out_features), requires_grad=True)\n",
        "\n",
        "        self.initial_popup_scores = self.popup_scores.clone()\n",
        "        self.initial_bias_popup_scores = self.bias_popup_scores.clone()\n",
        "\n",
        "        # Initialize weights\n",
        "        if init == signed_kaiming_constant_:\n",
        "            init(self.weight, k=k)\n",
        "        else:\n",
        "            init(self.weight)\n",
        "\n",
        "        self.weight.requires_grad_(False)\n",
        "        if self.bias is not None:\n",
        "            self.bias.requires_grad_(False)\n",
        "    def return_to_initial_popup_scores(self):\n",
        "        self.popup_scores = nn.Parameter(self.initial_popup_scores.clone(),requires_grad=True)\n",
        "        self.bias_popup_scores = nn.Parameter(self.initial_bias_popup_scores.clone(),requires_grad=True)\n",
        "        print('Popup Scores Returned to Initial Values')\n",
        "\n",
        "    def forward(self, x):\n",
        "        adj = GetSubnet.apply(\n",
        "            torch.cat((self.popup_scores.abs(),self.popup_scores_extra.abs()),dim=-1), self.k\n",
        "        )[:, :self.weight.shape[-1]]\n",
        "        bias_adj = GetSubnet.apply(\n",
        "            torch.cat((self.bias_popup_scores.abs(),self.bias_popup_scores_extra.abs()), dim=-1), self.k\n",
        "        )[:self.bias.shape[-1]]\n",
        "\n",
        "        w = self.weight * adj\n",
        "        b = self.bias * bias_adj\n",
        "\n",
        "\n",
        "        return F.linear(x, w, b)\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, layer_sizes, k=0.5, init=signed_kaiming_constant_):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i, (in_f, out_f) in enumerate(layer_sizes):\n",
        "            self.layers.append(LinearSubnet(in_f, out_f,k=k,init=init))\n",
        "            if i < len(layer_sizes) - 1:\n",
        "                self.layers.append(nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[1:] != (3, 28, 28):\n",
        "          print(x.shape)\n",
        "          x.unsqueeze_(0)\n",
        "          x = x.repeat(3, 1, 1)\n",
        "        x = self.flatten(x)\n",
        "        for layer in self.layers:\n",
        "                x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YfKVfA_p74A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskAE(nn.Module):\n",
        "    \"\"\"Small MLP autoencoder for flattened doubled masks of length D.\"\"\"\n",
        "    def __init__(self, D, embed_dim=32):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(D, max(128, embed_dim*2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(max(128, embed_dim*2), embed_dim),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, max(128, embed_dim*2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(max(128, embed_dim*2), D)   # raw logits for masks\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        y = self.decoder(z)\n",
        "        return y\n",
        "\n",
        "    def encode(self, x):  # x: [B, D]\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):  # z: [B, E]\n",
        "        return self.decoder(z)\n",
        "\n",
        "# linear subnet that passes info about it's masking\n",
        "class LinearSubnetFlow(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, bias=True, k=0.5, init=signed_kaiming_constant_, **kwargs):\n",
        "        super().__init__(in_features, out_features, bias if isinstance(bias, bool) else True, **kwargs)\n",
        "\n",
        "        self.k = k\n",
        "        self.popup_scores = nn.Parameter(torch.randn(out_features, in_features), requires_grad=True)\n",
        "        self.bias_popup_scores = nn.Parameter(torch.randn(out_features), requires_grad=True)\n",
        "        self.popup_scores_extra = nn.Parameter(torch.randn(out_features, in_features), requires_grad=True)\n",
        "        self.bias_popup_scores_extra = nn.Parameter(torch.randn(out_features), requires_grad=True)\n",
        "\n",
        "        self.initial_popup_scores = self.popup_scores.clone()\n",
        "        self.initial_bias_popup_scores = self.bias_popup_scores.clone()\n",
        "\n",
        "        # Initialize weights\n",
        "        if init == signed_kaiming_constant_:\n",
        "            init(self.weight, k=k)\n",
        "        else:\n",
        "            init(self.weight)\n",
        "\n",
        "        self.weight.requires_grad_(False)\n",
        "        if self.bias is not None:\n",
        "            self.bias.requires_grad_(False)\n",
        "    def return_to_initial_popup_scores(self):\n",
        "        self.popup_scores = nn.Parameter(self.initial_popup_scores.clone(),requires_grad=True)\n",
        "        self.bias_popup_scores = nn.Parameter(self.initial_bias_popup_scores.clone(),requires_grad=True)\n",
        "        print('Popup Scores Returned to Initial Values')\n",
        "\n",
        "    def forward(self, x, AE: MaskAE, prev_mask_emb=None):\n",
        "        if prev_mask_emb is not None:\n",
        "            # expand or project mask_emb to match x’s shape\n",
        "            if prev_mask_emb.dim() == 1:\n",
        "                prev_mask_emb = prev_mask_emb.unsqueeze(0).expand(x.size(0), -1)\n",
        "            x = self.mask_adapter(torch.cat((x, prev_mask_emb), dim=-1))\n",
        "\n",
        "        adj = GetSubnet.apply(\n",
        "            torch.cat((self.popup_scores.abs(),self.popup_scores_extra.abs()),dim=-1), self.k\n",
        "        )[:, :self.weight.shape[-1]]\n",
        "        bias_adj = GetSubnet.apply(\n",
        "            torch.cat((self.bias_popup_scores.abs(),self.bias_popup_scores_extra.abs()), dim=-1), self.k\n",
        "        )[:self.bias.shape[-1]]\n",
        "\n",
        "        w = self.weight * adj\n",
        "        b = self.bias * bias_adj\n",
        "\n",
        "        mask_emb = MaskAE.encode(w)\n",
        "\n",
        "\n",
        "        return F.linear(x, w, b), mask_emb\n",
        "\n",
        "\n",
        "class FlowNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes, AE, k=0.5, init=signed_kaiming_constant_):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i, (in_f, out_f) in enumerate(layer_sizes):\n",
        "            self.layers.append(LinearSubnetFlow(in_f, out_f,k=k,init=init))\n",
        "            if i < len(layer_sizes) - 1:\n",
        "                self.layers.append(nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[1:] != (3, 28, 28):\n",
        "          print(x.shape)\n",
        "          x.unsqueeze_(0)\n",
        "          x = x.repeat(3, 1, 1)\n",
        "        x = self.flatten(x)\n",
        "        for layer in self.layers:\n",
        "                x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Q6f5ItlLL1k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training mask autoencoder\n",
        "class MaskAE(nn.Module):\n",
        "    \"\"\"Small MLP autoencoder for flattened doubled masks of length D.\"\"\"\n",
        "    def __init__(self, D, embed_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(D, max(128, embed_dim*2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(max(128, embed_dim*2), embed_dim),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, max(128, embed_dim*2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(max(128, embed_dim*2), D)   # raw logits for masks\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        y = self.decoder(z)\n",
        "        return y\n",
        "\n",
        "    def encode(self, x):  # x: [B, D]\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):  # z: [B, E]\n",
        "        return self.decoder(z)\n",
        "\n",
        "class MasksOnlyDataset(Dataset):\n",
        "    def __init__(self, targets):  # targets: [N, D] of {0,1}\n",
        "        self.targets = targets\n",
        "    def __len__(self): return self.targets.size(0)\n",
        "    def __getitem__(self, i):\n",
        "        t = self.targets[i]\n",
        "        return t, t  # (input=mask, target=mask)\n",
        "\n",
        "def train_autoencoder_on_masks(targets,\n",
        "                               D,            # flattened doubled length = out_f*(2*in_f) + 2*out_f\n",
        "                               in_f, out_f,  # layer shape\n",
        "                               k,            # keep ratio used by GetSubnet\n",
        "                               embed_dim=64,\n",
        "                               epochs=20,\n",
        "                               batch=256,\n",
        "                               lr=1e-3,\n",
        "                               device='cpu',\n",
        "                               aux_logit_loss_weight=0.0):\n",
        "    \"\"\"\n",
        "    targets: [N, D] binary doubled masks (weight: [out, 2*in], bias: [2*out], flattened)\n",
        "    Trains AE so that decoder(pred_z) -> logits -> GetSubnet(k) matches targets.\n",
        "    Optionally adds a tiny auxiliary loss on logits (post-sigmoid) for stability.\n",
        "    \"\"\"\n",
        "    ds = MasksOnlyDataset(targets)  # (mask, mask)\n",
        "    loader = DataLoader(ds, batch_size=batch, shuffle=True)\n",
        "\n",
        "    ae = MaskAE(D, embed_dim).to(device)\n",
        "    opt = torch.optim.Adam(ae.parameters(), lr=lr)\n",
        "\n",
        "    D_w = out_f * (2 * in_f)\n",
        "    D_b = 2 * out_f\n",
        "\n",
        "    ae.train()\n",
        "    for _ in range(epochs):\n",
        "        for m_in, m_tgt in loader:\n",
        "            m_in, m_tgt = m_in.to(device), m_tgt.to(device)  # [B, D], {0,1}\n",
        "\n",
        "            logits = ae(m_in)  # [B, D]\n",
        "\n",
        "            # Split & reshape to doubled shapes, mirror router path\n",
        "            w_logits = logits[:, :D_w].reshape(-1, out_f, 2*in_f).abs()\n",
        "            b_logits = logits[:, D_w:].reshape(-1, 2*out_f).abs()\n",
        "\n",
        "            # STE top-k to binarize\n",
        "            w_mask_hat = GetSubnet.apply(w_logits, k)    # [B, out, 2*in] in {0,1}\n",
        "            b_mask_hat = GetSubnet.apply(b_logits, k)    # [B, 2*out]   in {0,1}\n",
        "\n",
        "            pred_mask = torch.cat([w_mask_hat.reshape(logits.size(0), -1),\n",
        "                                   b_mask_hat.reshape(logits.size(0), -1)], dim=1)  # [B, D]\n",
        "\n",
        "            # Primary loss: match binary masks after GetSubnet\n",
        "            loss = F.mse_loss(pred_mask, m_tgt)\n",
        "\n",
        "            # Optional tiny auxiliary term (can help stabilize training a bit)\n",
        "            if aux_logit_loss_weight > 0.0:\n",
        "                loss = loss + aux_logit_loss_weight * F.mse_loss(torch.sigmoid(logits), m_tgt)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    # freeze decoder head\n",
        "    for p in ae.decoder.parameters():\n",
        "        p.requires_grad = False\n",
        "    ae.eval()\n",
        "    return ae, ae.decoder\n",
        "\n",
        "def train_autoencoders_for_all_layers(datasets_per_layer,\n",
        "                                      layer_sizes,\n",
        "                                      embed_dims,\n",
        "                                      k=0.5,\n",
        "                                      epochs=20,\n",
        "                                      batch=256,\n",
        "                                      lr=1e-3,\n",
        "                                      device='cpu',\n",
        "                                      aux_logit_loss_weight=0.0):\n",
        "    \"\"\"\n",
        "    Returns: (decoders_frozen, full_AEs)\n",
        "    Each dataset[i].targets is [N, D_i] with doubled masks.\n",
        "    \"\"\"\n",
        "    if isinstance(embed_dims, int):\n",
        "        embed_dims = [embed_dims] * len(layer_sizes)\n",
        "\n",
        "    decoders, aes = [], []\n",
        "    for (in_f, out_f), ds, E in zip(layer_sizes, datasets_per_layer, embed_dims):\n",
        "        D = out_f * (2 * in_f) + 2 * out_f\n",
        "        all_masks = ds.targets.to(device)  # [N, D], {0,1}\n",
        "\n",
        "        ae, decoder = train_autoencoder_on_masks(\n",
        "            targets=all_masks,\n",
        "            D=D,\n",
        "            in_f=in_f,\n",
        "            out_f=out_f,\n",
        "            k=k,\n",
        "            embed_dim=E,\n",
        "            epochs=epochs,\n",
        "            batch=batch,\n",
        "            lr=lr,\n",
        "            device=device,\n",
        "            aux_logit_loss_weight=aux_logit_loss_weight\n",
        "        )\n",
        "        decoders.append(decoder)  # frozen\n",
        "        aes.append(ae)\n",
        "\n",
        "    return decoders, aes"
      ],
      "metadata": {
        "id": "bHRUO4zrQKaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a training function that returns a list of the losses during training.\n",
        "def trainit(model,\n",
        "            NUM_EPOCHS,\n",
        "            train_loader,\n",
        "            optimizer,\n",
        "            task,\n",
        "            n_classes,\n",
        "            return_losses=False,\n",
        "            no_progress=False):\n",
        "  # define loss function\n",
        "  if task == \"multi-label, binary-class\":\n",
        "      criterion = nn.BCEWithLogitsLoss()\n",
        "  else:\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "  if return_losses:\n",
        "      losses = []\n",
        "  # iterate over epochs for training run\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "      model.train()\n",
        "      if no_progress:\n",
        "        loader = train_loader\n",
        "      else:\n",
        "        loader=tqdm(train_loader)\n",
        "      for inputs, targets in loader:\n",
        "          inputs  = inputs.to(device, non_blocking=True)\n",
        "          targets = targets.to(device, non_blocking=True)\n",
        "          # forward + backward + optimize\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)[:,0:n_classes]\n",
        "          if task == 'multi-label, binary-class':\n",
        "              targets = targets.to(torch.float32)\n",
        "              loss = criterion(outputs, targets)\n",
        "          else:\n",
        "              targets = targets.squeeze(1)\n",
        "              loss = criterion(outputs, targets)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if return_losses:\n",
        "              losses.append(loss.item())\n",
        "  if return_losses:\n",
        "      return losses\n",
        "\n",
        "# Define an evaluation function\n",
        "def test(split,\n",
        "         model,\n",
        "         train_loader_at_eval,\n",
        "         test_loader,\n",
        "         task,\n",
        "         n_classes,\n",
        "         data_flag,\n",
        "         return_metrics=False):\n",
        "    # define loss function\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([])\n",
        "    y_score = torch.tensor([])\n",
        "\n",
        "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            # inputs  = inputs.to(device, non_blocking=True)\n",
        "            # targets = targets.to(device, non_blocking=True)\n",
        "            outputs = model(inputs)[:,0:n_classes]\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze(1)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_true = y_true.numpy()\n",
        "        y_score = y_score.detach().numpy()\n",
        "\n",
        "        evaluator = Evaluator(data_flag, split)\n",
        "        metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
        "\n",
        "        if return_metrics:\n",
        "          return metrics"
      ],
      "metadata": {
        "id": "oUaM9_BmmTe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")\n",
        "data_set_name = 'breastmnist'\n",
        "info, task, n_classes, train_loader, train_loader_at_eval, test_loader = getTrainingDataLoaders(data_set_name)\n",
        "layer_sizes=[[3*28*28, 256],[256,256],[256, n_classes]]\n",
        "NUM_EPOCHS = 1000\n",
        "\n",
        "model = Network(layer_sizes=layer_sizes,k=0.5)\n",
        "model.to(device)\n",
        "router_train_score=[]\n",
        "\n",
        "losses=trainit(model,NUM_EPOCHS,train_loader,optim.Adam(model.parameters()),task='multi-class',n_classes=14, return_losses=True)\n",
        "router_train_score.append(losses)\n",
        "\n",
        "flow_model = FlowNetwork(layer_sizes=layer_sizes,k=0.5)\n",
        "flow_model.to(device)\n",
        "flow_train_score=[]\n",
        "losses=trainit(flow_model,NUM_EPOCHS,train_loader,optim.Adam(model.parameters()),task='multi-class',n_classes=14, return_losses=True)\n",
        "flow_train_score.append(losses)\n",
        "\n",
        "\n",
        "classicmodel = ClassicNetwork(layer_sizes=layer_sizes)\n",
        "classicmodel.to(device)\n",
        "classic_train_score=[]\n",
        "losses=trainit(classicmodel,NUM_EPOCHS,train_loader,optim.Adam(classicmodel.parameters()),task='multi-class',n_classes=14, return_losses=True)\n",
        "classic_train_score.append(losses)\n",
        "\n",
        "plt.plot(router_train_score[0], label='Masking')\n",
        "plt.plot(flow_train_score[0], label='Flow Masking')\n",
        "plt.plot(classic_train_score[0], label='Classical')\n",
        "plt.legend()\n",
        "ax = plt.gca()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "# plt.yscale('log')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lnGvSGAkmWyV",
        "outputId": "de3c9dd4-eaa5-4de9-b088-3e1bd7de9222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 560k/560k [00:01<00:00, 481kB/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.41it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.05it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.92it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.78it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.79it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.75it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.81it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.80it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.75it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.71it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.90it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.89it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.74it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.69it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.77it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.78it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.75it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.74it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.80it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.88it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.06it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.80it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.70it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.78it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.68it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.74it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.73it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.11it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.72it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.78it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.68it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.77it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.80it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.62it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.73it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.30it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.51it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.03it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.80it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.82it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.79it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.76it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.11it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.83it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.68it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.71it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.71it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.58it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.70it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.27it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.79it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.85it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.66it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.70it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.69it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.72it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.78it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.08it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.64it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.68it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.69it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.75it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.75it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.78it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.51it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.72it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.33it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.67it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.70it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.69it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.65it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.68it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.79it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.21it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  2.61it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.72it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.70it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.64it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.42it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
            " 20%|██        | 1/5 [00:00<00:01,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2282523141.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mrouter_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multi-class'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_losses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mrouter_train_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-19642613.py\u001b[0m in \u001b[0;36mtrainit\u001b[0;34m(model, NUM_EPOCHS, train_loader, optimizer, task, n_classes, return_losses, no_progress)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m           \u001b[0minputs\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/medmnist/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/v2/_container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mneeds_unpacking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mneeds_unpacking\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/v2/_transform.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         flat_outputs = [\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mneeds_transform\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_transform\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_transform_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/v2/_misc.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, inpt, params)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/v2/_transform.py\u001b[0m in \u001b[0;36m_call_kernel\u001b[0;34m(self, functional, inpt, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_passthrough\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/v2/functional/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(inpt, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# lost after the first operation due to our own __torch_function__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_subclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtv_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/v2/functional/_misc.py\u001b[0m in \u001b[0;36mnormalize_image\u001b[0;34m(image, mean, std, inplace)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}